{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAR brandclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning VGG 16 and VGG 19 using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### car brand classification Train data and test data\n",
    "Train data consists of - 3 brand cars -audi,lamborghini, mercedes class\n",
    "each folder consists of audi - 20 images; lamborghini - 19 cars; mercedes - 25\n",
    "\n",
    "Test data consists of -audi - 9 ; lamborghini - 30 ; mercedes - 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is transfer learning \n",
    "Transfer learning is a research problem in machine learning that focuses on storing knowledge \n",
    "gained while solving one problem and applying it to a different but related problem.\n",
    "\n",
    "Transfer learning is a machine learning method where a model developed for a task is reused \n",
    "as the starting point for a model on a second task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use Transfer Learning?\n",
    "You can use transfer learning on your own predictive modeling problems.\n",
    "\n",
    "Two common approaches are as follows:\n",
    "\n",
    "### Develop Model Approach\n",
    "### Pre-trained Model Approach\n",
    "### Develop Model Approach\n",
    "Select Source Task. You must select a related predictive modeling problem with an abundance of data where there is some relationship in the input data, output data, and/or concepts learned during the mapping from input to output data.\n",
    "Develop Source Model. Next, you must develop a skillful model for this first task. The model must be better than a naive model to ensure that some feature learning has been performed.\n",
    "Reuse Model. The model fit on the source task can then be used as the starting point for a model on the second task of interest. This may involve using all or parts of the model, depending on the modeling technique used.\n",
    "Tune Model. Optionally, the model may need to be adapted or refined on the input-output pair data available for the task of interest.\n",
    "### Pre-trained Model Approach\n",
    "Select Source Model. A pre-trained source model is chosen from available models. Many research institutions release models on large and challenging datasets that may be included in the pool of candidate models from which to choose from.\n",
    "Reuse Model. The model pre-trained model can then be used as the starting point for a model on the second task of interest. This may involve using all or parts of the model, depending on the modeling technique used.\n",
    "Tune Model. Optionally, the model may need to be adapted or refined on the input-output pair data available for the task of interest.\n",
    "This second type of transfer learning is common in the field of deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "# IMAGE_SIZE = [224, 224] - width and height\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "train_path = 'Datasets/train'\n",
    "valid_path = 'Datasets/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 493s 5us/step\n"
     ]
    }
   ],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "# IMAGE_SIZE + [3] - 3 channels RGB\n",
    "# include_top = False we have to include our own dataset as input and output our own number of classes  \n",
    "\n",
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights - reuse those weights from resnet\n",
    "# don't retrain the mdoel just reuse all layers but not last layer\n",
    "#\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Datasets/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "# in test data we should not use augmentation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Datasets/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Datasets/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 26.6794 - acc: 0.3276\n",
      "2/2 [==============================] - 25s 13s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 26.6794 - val_acc: 0.3276\n",
      "Epoch 2/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 27.1257 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 27.1257 - val_acc: 0.3276\n",
      "Epoch 3/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 27.2658 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 27.2658 - val_acc: 0.3276\n",
      "Epoch 4/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 26.8975 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 1.8681e-06 - acc: 1.0000 - val_loss: 26.8975 - val_acc: 0.3276\n",
      "Epoch 5/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 27.8014 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 27.8014 - val_acc: 0.3276\n",
      "Epoch 6/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 28.3173 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 28.3173 - val_acc: 0.3276\n",
      "Epoch 7/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 3.7253e-09 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 28.2137 - acc: 0.3276\n",
      "2/2 [==============================] - 25s 13s/step - loss: 3.7253e-09 - acc: 1.0000 - val_loss: 28.2137 - val_acc: 0.3276\n",
      "Epoch 8/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 26.6823 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 0.0016 - acc: 1.0000 - val_loss: 26.6823 - val_acc: 0.3276\n",
      "Epoch 9/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 23.3783 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 23.3783 - val_acc: 0.3276\n",
      "Epoch 10/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 2.1200e-04 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 22.7433 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 1.0600e-04 - acc: 1.0000 - val_loss: 22.7433 - val_acc: 0.3276\n",
      "Epoch 11/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 3.7253e-08 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 26.5505 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 0.4510 - acc: 0.9531 - val_loss: 26.5505 - val_acc: 0.3276\n",
      "Epoch 12/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 2.6449e-07 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 32.8237 - acc: 0.3276\n",
      "2/2 [==============================] - 23s 12s/step - loss: 1.3225e-07 - acc: 1.0000 - val_loss: 32.8237 - val_acc: 0.3276\n",
      "Epoch 13/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0342 - acc: 0.9688Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 33.4468 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.1902 - acc: 0.9688 - val_loss: 33.4468 - val_acc: 0.3276\n",
      "Epoch 14/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 33.4183 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 1.8626e-09 - acc: 1.0000 - val_loss: 33.4183 - val_acc: 0.3276\n",
      "Epoch 15/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 33.2849 - acc: 0.3276\n",
      "2/2 [==============================] - 26s 13s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 33.2849 - val_acc: 0.3276\n",
      "Epoch 16/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 8.4851e-06 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 32.1677 - acc: 0.3276\n",
      "2/2 [==============================] - 28s 14s/step - loss: 4.2425e-06 - acc: 1.0000 - val_loss: 32.1677 - val_acc: 0.3276\n",
      "Epoch 17/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 31.8925 - acc: 0.3276\n",
      "2/2 [==============================] - 26s 13s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 31.8925 - val_acc: 0.3276\n",
      "Epoch 18/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 32.1263 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 32.1263 - val_acc: 0.3276\n",
      "Epoch 19/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 4.9173e-07 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 31.5980 - acc: 0.3276\n",
      "2/2 [==============================] - 28s 14s/step - loss: 2.4587e-07 - acc: 1.0000 - val_loss: 31.5980 - val_acc: 0.3276\n",
      "Epoch 20/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 31.9022 - acc: 0.3276\n",
      "2/2 [==============================] - 26s 13s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 31.9022 - val_acc: 0.3276\n",
      "Epoch 21/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 3.3705e-04 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 31.9453 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 1.6853e-04 - acc: 1.0000 - val_loss: 31.9453 - val_acc: 0.3276\n",
      "Epoch 22/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 32.4862 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0011 - acc: 1.0000 - val_loss: 32.4862 - val_acc: 0.3276\n",
      "Epoch 23/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 33.2561 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 33.2561 - val_acc: 0.3276\n",
      "Epoch 24/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 4.8429e-08 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 33.5418 - acc: 0.3276\n",
      "2/2 [==============================] - 26s 13s/step - loss: 2.4214e-08 - acc: 1.0000 - val_loss: 33.5418 - val_acc: 0.3276\n",
      "Epoch 25/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.1585 - acc: 0.9688Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 34.9100 - acc: 0.3276\n",
      "2/2 [==============================] - 25s 13s/step - loss: 0.0793 - acc: 0.9844 - val_loss: 34.9100 - val_acc: 0.3276\n",
      "Epoch 26/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 36.0012 - acc: 0.3276\n",
      "2/2 [==============================] - 32s 16s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 36.0012 - val_acc: 0.3276\n",
      "Epoch 27/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 37.4882 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 14s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 37.4882 - val_acc: 0.3276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 38.2052 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 1.6764e-08 - acc: 1.0000 - val_loss: 38.2052 - val_acc: 0.3276\n",
      "Epoch 29/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 3.5248e-04 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 37.7374 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 1.7624e-04 - acc: 1.0000 - val_loss: 37.7374 - val_acc: 0.3276\n",
      "Epoch 30/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 1.8924e-06 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 37.4502 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 14s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 37.4502 - val_acc: 0.3276\n",
      "Epoch 31/50\n",
      "1/2 [==============>...............] - ETA: 10s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 37.6763 - acc: 0.3276\n",
      "2/2 [==============================] - 25s 13s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 37.6763 - val_acc: 0.3276\n",
      "Epoch 32/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 37.7078 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 37.7078 - val_acc: 0.3276\n",
      "Epoch 33/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 37.0114 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 1.8626e-09 - acc: 1.0000 - val_loss: 37.0114 - val_acc: 0.3276\n",
      "Epoch 34/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 36.8157 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 36.8157 - val_acc: 0.3276\n",
      "Epoch 35/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 38.3683 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 38.3683 - val_acc: 0.3276\n",
      "Epoch 36/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 2s/step - loss: 37.2286 - acc: 0.3276\n",
      "2/2 [==============================] - 24s 12s/step - loss: 1.5310e-06 - acc: 1.0000 - val_loss: 37.2286 - val_acc: 0.3276\n",
      "Epoch 37/50\n",
      "1/2 [==============>...............] - ETA: 9s - loss: 3.7253e-09 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 37.8053 - acc: 0.3276\n",
      "2/2 [==============================] - 27s 13s/step - loss: 1.8626e-09 - acc: 1.0000 - val_loss: 37.8053 - val_acc: 0.3276\n",
      "Epoch 38/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 37.0514 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.0061 - acc: 1.0000 - val_loss: 37.0514 - val_acc: 0.3276\n",
      "Epoch 39/50\n",
      "1/2 [==============>...............] - ETA: 13s - loss: 1.4901e-08 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 35.2085 - acc: 0.3276\n",
      "2/2 [==============================] - 32s 16s/step - loss: 7.4506e-09 - acc: 1.0000 - val_loss: 35.2085 - val_acc: 0.3276\n",
      "Epoch 40/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 34.1440 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 34.1440 - val_acc: 0.3276\n",
      "Epoch 41/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 33.4028 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 33.4028 - val_acc: 0.3276\n",
      "Epoch 42/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 31.5089 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 31.5089 - val_acc: 0.3276\n",
      "Epoch 43/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 3.6562e-04 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 32.4350 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 1.8281e-04 - acc: 1.0000 - val_loss: 32.4350 - val_acc: 0.3276\n",
      "Epoch 44/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 32.9529 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.1094 - acc: 0.9844 - val_loss: 32.9529 - val_acc: 0.3276\n",
      "Epoch 45/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 35.7361 - acc: 0.3276\n",
      "2/2 [==============================] - 31s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 35.7361 - val_acc: 0.3276\n",
      "Epoch 46/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 37.9202 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 37.9202 - val_acc: 0.3276\n",
      "Epoch 47/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 3.5018e-07 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 38.8321 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 1.7509e-07 - acc: 1.0000 - val_loss: 38.8321 - val_acc: 0.3276\n",
      "Epoch 48/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 40.0570 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 2.1234e-07 - acc: 1.0000 - val_loss: 40.0570 - val_acc: 0.3276\n",
      "Epoch 49/50\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 5s 3s/step - loss: 39.2112 - acc: 0.3276\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.2799 - acc: 0.9844 - val_loss: 39.2112 - val_acc: 0.3276\n",
      "Epoch 50/50\n",
      "1/2 [==============>...............] - ETA: 12s - loss: 0.0000e+00 - acc: 1.0000Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 37.1023 - acc: 0.3276\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 37.1023 - val_acc: 0.3276\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "# what is epoch - \n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can see loss,validation loss,valicdation accuracy, accuracy...\n",
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2281111e-26, 1.2584345e-25, 1.0000000e+00],\n",
       "       [5.7013246e-25, 5.0343003e-25, 1.0000000e+00],\n",
       "       [4.4075246e-25, 8.6745995e-25, 1.0000000e+00],\n",
       "       [3.8885883e-25, 2.1096852e-25, 1.0000000e+00],\n",
       "       [7.6663789e-26, 1.7028080e-25, 1.0000000e+00],\n",
       "       [4.7028594e-25, 7.3667002e-25, 1.0000000e+00],\n",
       "       [5.7185507e-26, 1.9625985e-25, 1.0000000e+00],\n",
       "       [1.8259554e-24, 2.9903816e-24, 1.0000000e+00],\n",
       "       [1.0704353e-23, 5.8202998e-24, 1.0000000e+00],\n",
       "       [2.1425821e-24, 2.4288455e-24, 1.0000000e+00],\n",
       "       [2.4663684e-25, 3.6616004e-24, 1.0000000e+00],\n",
       "       [3.2171927e-25, 1.4625018e-25, 1.0000000e+00],\n",
       "       [7.2013155e-27, 1.2389013e-24, 1.0000000e+00],\n",
       "       [3.2196129e-24, 2.7823067e-24, 1.0000000e+00],\n",
       "       [4.1639105e-26, 1.1540250e-25, 1.0000000e+00],\n",
       "       [4.1148344e-26, 1.0516019e-25, 1.0000000e+00],\n",
       "       [1.8475206e-25, 8.4782068e-26, 1.0000000e+00],\n",
       "       [7.4102413e-26, 2.3323866e-25, 1.0000000e+00],\n",
       "       [4.7249593e-25, 7.8281823e-25, 1.0000000e+00],\n",
       "       [1.5320750e-25, 6.2418348e-26, 1.0000000e+00],\n",
       "       [1.2757482e-25, 2.9135182e-25, 1.0000000e+00],\n",
       "       [1.5909856e-26, 1.3619022e-25, 1.0000000e+00],\n",
       "       [4.2542121e-24, 4.5475930e-24, 1.0000000e+00],\n",
       "       [7.0282280e-25, 1.8162091e-24, 1.0000000e+00],\n",
       "       [2.0188126e-25, 4.2492282e-26, 1.0000000e+00],\n",
       "       [7.7241828e-25, 2.1363539e-25, 1.0000000e+00],\n",
       "       [7.4122776e-26, 1.3680464e-25, 1.0000000e+00],\n",
       "       [9.3747252e-24, 3.9334975e-24, 1.0000000e+00],\n",
       "       [2.1004745e-25, 1.4715229e-25, 1.0000000e+00],\n",
       "       [9.3602478e-25, 4.5284986e-24, 1.0000000e+00],\n",
       "       [8.9532681e-26, 6.1480683e-25, 1.0000000e+00],\n",
       "       [4.9129370e-25, 1.7805097e-24, 1.0000000e+00],\n",
       "       [1.7053823e-25, 1.1963031e-25, 1.0000000e+00],\n",
       "       [3.5206249e-26, 1.6628123e-23, 1.0000000e+00],\n",
       "       [1.9708211e-25, 1.6752012e-24, 1.0000000e+00],\n",
       "       [1.3318568e-25, 2.6291224e-26, 1.0000000e+00],\n",
       "       [1.1289920e-25, 1.6120141e-25, 1.0000000e+00],\n",
       "       [7.1842530e-26, 1.7998072e-25, 1.0000000e+00],\n",
       "       [2.4058084e-26, 4.2321318e-25, 1.0000000e+00],\n",
       "       [1.9627482e-25, 8.4910927e-25, 1.0000000e+00],\n",
       "       [1.2245145e-24, 1.1341639e-24, 1.0000000e+00],\n",
       "       [2.4107783e-26, 3.6877699e-25, 1.0000000e+00],\n",
       "       [7.6202563e-25, 9.0496240e-25, 1.0000000e+00],\n",
       "       [1.7618611e-25, 6.6365204e-26, 1.0000000e+00],\n",
       "       [2.3434903e-25, 2.0390365e-25, 1.0000000e+00],\n",
       "       [1.2776092e-24, 2.2268283e-24, 1.0000000e+00],\n",
       "       [2.6569511e-25, 2.6456738e-25, 1.0000000e+00],\n",
       "       [1.3662361e-26, 6.0437272e-26, 1.0000000e+00],\n",
       "       [3.0734171e-25, 2.2980578e-25, 1.0000000e+00],\n",
       "       [1.7644984e-24, 1.8938685e-24, 1.0000000e+00],\n",
       "       [4.6991497e-24, 3.8474971e-24, 1.0000000e+00],\n",
       "       [3.7906204e-25, 2.9364588e-25, 1.0000000e+00],\n",
       "       [1.5324016e-26, 4.6067788e-26, 1.0000000e+00],\n",
       "       [1.2950434e-24, 1.4744511e-24, 1.0000000e+00],\n",
       "       [3.0657590e-25, 3.3076902e-24, 1.0000000e+00],\n",
       "       [3.7631882e-25, 1.6238154e-24, 1.0000000e+00],\n",
       "       [2.5670338e-26, 4.4857688e-26, 1.0000000e+00],\n",
       "       [8.0413828e-25, 1.3332706e-24, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability based on 3 - classes \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which ever have highest \n",
    "import numpy as np\n",
    "#y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=load_model('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x8e067e4eb8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-103.25665 , -116.04175 , -122.91921 ],\n",
       "         [-103.16645 , -115.95939 , -122.83686 ],\n",
       "         [-103.06449 , -115.85743 , -122.7349  ]],\n",
       "\n",
       "        [[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-103.025276, -115.818214, -122.71137 ],\n",
       "         [-103.025276, -115.82998 , -122.719215],\n",
       "         [-103.0292  , -115.8339  , -122.72314 ]],\n",
       "\n",
       "        [[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-102.993904, -115.80645 , -122.719215],\n",
       "         [-102.96645 , -115.79861 , -122.72314 ],\n",
       "         [-102.96645 , -115.79861 , -122.72314 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-103.04096 , -115.97115 , -122.934906],\n",
       "         [-103.04096 , -115.97115 , -122.934906],\n",
       "         [-103.04096 , -115.97115 , -122.934906],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07704 , -123.00549 ],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]],\n",
       "\n",
       "        [[-103.048805, -115.975075, -122.94667 ],\n",
       "         [-103.048805, -115.975075, -122.94667 ],\n",
       "         [-103.048805, -115.975075, -122.94667 ],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07704 , -123.00549 ],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]],\n",
       "\n",
       "        [[-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.975075, -122.94667 ],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07704 , -123.00549 ],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]]]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Datasets/Test/lamborghini/11.jpg',target_size=(224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [194., 188., 174.],\n",
       "        [215., 209., 197.],\n",
       "        [241., 235., 223.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [247., 245., 233.],\n",
       "        [245., 242., 233.],\n",
       "        [244., 241., 232.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [245., 248., 241.],\n",
       "        [244., 250., 248.],\n",
       "        [244., 250., 248.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[187., 205., 227.],\n",
       "        [187., 205., 227.],\n",
       "        [187., 205., 227.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [187., 205., 227.],\n",
       "        ...,\n",
       "        [172., 179., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.200653e-15, 6.741602e-13, 1.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
